---
title: "Exploring Labour data"
format: 
  html:
    toc: true
jupyter: python3
editor: 
  render-on-save: true
---

# Setup

## Libraries

```{python}
import polars as pl
import polars.selectors as cs
from pyprojroot import here
from great_tables import GT, md, html
from plotnine import *
```

## Data

Load data lazily because it is 2.5 Gb

```{python}
FILE = here() / "data" / "14100022.csv"
labour = (

    # lazy read in and filter / drop columns
    pl.scan_csv(FILE)
    .drop(
        ['UOM_ID', 'DGUID', 'SCALAR_FACTOR', 'SCALAR_ID', 'VECTOR', 'COORDINATE', 'STATUS', 'SYMBOL', 'TERMINATED', 'DECIMALS'])
    .filter(
        pl.col('Labour force characteristics') == 'Employment',
        ~pl.col('North American Industry Classification System (NAICS)').is_in(
            ['Total, all industries', 'Unclassified industries']
        ),
        pl.col('GEO') == 'Canada',
        pl.col('Gender') == 'Total - Gender',
        pl.col('Age group') == '25 to 54 years',
        pl.col('UOM') == 'Persons in thousands'
    )
    .drop([
        'Labour force characteristics',
        'GEO',
        'Gender',
        'Age group',
        'UOM'
    ])
    .with_columns(pl.col('VALUE').cast(pl.Float64))

    # define Date columns
    .with_columns(
        pl.col('REF_DATE').str.extract(r'^(\d+)').cast(pl.Int32).alias('YEAR'),
        pl.col('REF_DATE').str.extract(r'(\d+)$').cast(pl.Int32).alias('MONTH')
    )
    .with_columns(
        pl.date(pl.col('YEAR'), pl.col('MONTH'), 1).alias('DATE_YMD')
    )
    .sort(['YEAR', 'MONTH'])
    .collect()
)
labour.glimpse()
```

# Process data

For our graphic, we need to make this variable: **signed rank in change in # of jobs**

Per month

Check that each year has 12 months:

```{python}
GT(labour.select('YEAR', 'MONTH').unique().group_by('YEAR').len())
```

## % Change per month

First, compute % change from previous month

```{python}
labour_processed = (
    labour
    .filter(pl.col('YEAR') >= 2020)
    .rename({"North American Industry Classification System (NAICS)": "Industry"})

    # if we sort acesnding by time, then lag value is the month before
    .sort(['Industry', 'YEAR', 'MONTH'])
    .with_columns(LAGGED_VALUE=pl.col("VALUE").shift(1).over('Industry'))

    # compute percent difference
    .with_columns((pl.col("VALUE") - pl.col("LAGGED_VALUE")).alias("DIFF"))
    .with_columns((pl.col("DIFF") / pl.col("LAGGED_VALUE")).alias("PDIFF"))
    .select(
        pl.col('Industry'),
        pl.col('DATE_YMD'),
        pl.col('YEAR'),
        pl.col('MONTH'), cs.matches('VALUE'), cs.matches('DIFF')
    )
    
    .sort(['Industry', 'YEAR', 'MONTH', 'PDIFF'])
)
labour_processed
```

## Signed rank

Now we can compute **Signed Asceending Rank of industry by % change**

*Signed* rank means that it is effectively computed over negative and positive %change separtely

e.g.

[-0.01, -0.02, 0.01, 0.02] = 
[-1, -2, 1, 2]


new solution

```{python}
def centered_rank_expr(col):
    """
    Expression version of your function - this is the recommended approach
    as it integrates better with Polars' lazy evaluation and optimization
    """
    return (
        pl.when(col < 0)
        .then(col.rank(method="ordinal", descending=True) * -1)
        .when(col == 0)
        .then(pl.lit(0))
        .when(col > 0)
        .then(col.rank(method="ordinal"))
        .otherwise(pl.lit(None))
    ).over(col < 0)


test_series = (
    labour_processed
    .with_columns(pl.col('PDIFF').round(decimals=4))
    .filter(pl.col('YEAR') == 2025, pl.col('MONTH') == 1)
    .select(pl.col('PDIFF'))
    .sample(n=10, seed=1)
    .select('PDIFF')
)

test_series.with_columns(centered_rank_expr(
    pl.col('PDIFF')).alias('rank')).sort('PDIFF')
```

```{python}
labour_processed = (
    labour_processed
    .with_columns(sign=pl.col('PDIFF').sign())
    .with_columns(
        signed_rank=(
            pl.col('sign')*pl.col('PDIFF').rank()).over(['YEAR', 'MONTH', 'sign']),
        centered_rank=centered_rank(pl.col('PDIFF')).over(['YEAR', 'MONTH'])
    )
)
labour_processed
```


```{python}
s  # check 1 year 1 month
(
    labour_processed
    .with_columns(pl.col('PDIFF').round(decimals=4))
    .filter(pl.col('YEAR') == 2025, pl.col('MONTH') == 1)
    .sort(['YEAR', 'MONTH', 'PDIFF'])
    .select(['PDIFF', 'signed_rank'])
)
```

```{python}
(
    ggplot(labour_processed, aes(x="DATE_YMD", y="signed_rank", color="PDIFF")) +
    geom_point(shape='s')
)
```


# Exploratory


```{python}

```